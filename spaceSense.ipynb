{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe1c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "675/675 [==============================] - 94s 137ms/step - loss: 1.2546 - accuracy: 0.5285 - val_loss: 0.9937 - val_accuracy: 0.6352\n",
      "Epoch 2/10\n",
      "675/675 [==============================] - 100s 147ms/step - loss: 0.8112 - accuracy: 0.7082 - val_loss: 0.7145 - val_accuracy: 0.7346\n",
      "Epoch 3/10\n",
      "675/675 [==============================] - 99s 146ms/step - loss: 0.6963 - accuracy: 0.7459 - val_loss: 0.5770 - val_accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "675/675 [==============================] - 98s 146ms/step - loss: 0.6285 - accuracy: 0.7733 - val_loss: 0.5787 - val_accuracy: 0.7930\n",
      "Epoch 5/10\n",
      "675/675 [==============================] - 99s 146ms/step - loss: 0.5739 - accuracy: 0.7928 - val_loss: 0.6715 - val_accuracy: 0.7593\n",
      "Epoch 6/10\n",
      "675/675 [==============================] - 101s 149ms/step - loss: 0.5191 - accuracy: 0.8133 - val_loss: 0.4925 - val_accuracy: 0.8254\n",
      "Epoch 7/10\n",
      "675/675 [==============================] - 102s 151ms/step - loss: 0.4825 - accuracy: 0.8261 - val_loss: 0.7361 - val_accuracy: 0.7454\n",
      "Epoch 8/10\n",
      "675/675 [==============================] - 103s 153ms/step - loss: 0.4438 - accuracy: 0.8413 - val_loss: 0.4460 - val_accuracy: 0.8389\n",
      "Epoch 9/10\n",
      "675/675 [==============================] - 105s 155ms/step - loss: 0.4029 - accuracy: 0.8560 - val_loss: 0.4089 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "675/675 [==============================] - 99s 146ms/step - loss: 0.3819 - accuracy: 0.8648 - val_loss: 0.4402 - val_accuracy: 0.8424\n",
      "Found 27000 images belonging to 10 classes.\n",
      "844/844 [==============================] - 61s 73ms/step - loss: 0.3757 - accuracy: 0.8650\n",
      "Test accuracy: 0.8650370240211487\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_dataset = data_generator.flow_from_directory(\n",
    "    'C:/Users/pc/Desktop/hey/2750',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = data_generator.flow_from_directory(\n",
    "    'C:/Users/pc/Desktop/hey/2750',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10\n",
    ")\n",
    "test_dataset = data_generator.flow_from_directory(\n",
    "    'C:/Users/pc/Desktop/hey/2750',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92a10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('spaceSenseModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd980942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "AnnualCrop_399.jpg: AnnualCrop\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AnnualCrop_1143.jpg: AnnualCrop\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Forest_2322.jpg: Forest\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Forest_1970.jpg: Forest\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "HerbaceousVegetation_291.jpg: HerbaceousVegetation\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "HerbaceousVegetation_303.jpg: HerbaceousVegetation\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Highway_2155.jpg: Highway\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Highway_1364.jpg: Highway\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Industrial_2338.jpg: Industrial\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Industrial_2207.jpg: Industrial\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Pasture_1364.jpg: Pasture\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Pasture_1620.jpg: Pasture\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "PermanentCrop_1358.jpg: Residential\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "PermanentCrop_1484.jpg: HerbaceousVegetation\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Residential_2514.jpg: Residential\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Residential_2092.jpg: Residential\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "River_16.jpg: River\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "River_1370.jpg: River\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "SeaLake_1527.jpg: SeaLake\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "SeaLake_499.jpg: SeaLake\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('spaceSenseModel.h5')\n",
    "\n",
    "# Define the image size\n",
    "img_size = (64, 64)\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_dir = 'C:/Users/pc/Desktop/hey/2750'\n",
    "\n",
    "# Get the list of class labels from the folder names\n",
    "class_labels = sorted(os.listdir(dataset_dir))\n",
    "\n",
    "# Loop through the class labels\n",
    "for class_label in class_labels:\n",
    "    \n",
    "    # Define the path to the folder for this class label\n",
    "    class_dir = os.path.join(dataset_dir, class_label)\n",
    "\n",
    "    # Get the list of filenames in this folder\n",
    "    filenames = os.listdir(class_dir)\n",
    "\n",
    "    # Select 2 random images from each class\n",
    "    random_filenames = random.sample(filenames, 2)\n",
    "\n",
    "    for filename in random_filenames:\n",
    "        # Load the image\n",
    "        img = load_img(\n",
    "            os.path.join(class_dir, filename),\n",
    "            target_size=img_size\n",
    "        )\n",
    "\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Normalize the image\n",
    "        img_array /= 255.\n",
    "\n",
    "        # Use the model to make a prediction\n",
    "        prediction = model.predict(img_array)\n",
    "\n",
    "        # Get the predicted class label\n",
    "        predicted_class_index = np.argmax(prediction[0])\n",
    "        predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "        # Print the filename and predicted class label\n",
    "        print(f'{filename}: {predicted_class_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712e328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
